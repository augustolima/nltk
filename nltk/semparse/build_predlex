#! /usr/bin/env python2.7

# ==================================================
# Builds a predicate dictionary from the CCG parses
# given in the input file (-i option) and saves it
# to the specified output file (-o option).
# ==================================================

from __future__ import print_function, unicode_literals

import io
import sys
import traceback
import optparse
import re
import string
from collections import defaultdict, namedtuple

#from nltk.semparse.semanticcategory import SemanticCategory
from semanticcategory import SemanticCategory ##


optparser = optparse.OptionParser()
optparser.add_option("-i", "--infile", dest="infile", default="", help="Input file")
optparser.add_option("-o", "--outfile", dest="outfile", default="", help="Output file")
optparser.add_option("--questions", dest="questions", action="store_true",
                     default=False, help="Use rules for questions.")
(opts, _) = optparser.parse_args()



# =============================================
# Step 1: Read in the CCG parses from the file.
# =============================================

def get_parses(infile):
    """
    Read in the parses file.

    param str infile: path to parses file.
    returns list(list) of parses split into dependencies and tags.
    """
    # Open file and split at each parse.
    parses = io.open(infile, 'rt', encoding='utf-8').read().split('\n===\n')
    # Split each parse between dependencies and tags.
    parses = [parse.split('\n<c> ') for parse in parses]
    # Split at each dependency.
    parses = [[deps.split('\n'), tags.split()] for (deps, tags) in parses]
    return parses


# =============================================================
# Step 2: Extract information from parses and pair it to words.
# =============================================================

def preprocess_word(word):
    """
    Makes word NLTK friendly.
    """
    # Remove numeric index.
    word = word.split('_')[0]
    # Remove intraword punctuation.
    for punct in string.punctuation:
        word = word.replace(punct, '')
    return word

def build_catLex(parses):
    """
    Builds lexicon of categories for each word in parses.

    param list(list) parses: output of get_parses().
    returns dict{word: namedtuple(pos_tag, category, dependencies)
    """
    catLex = defaultdict(list)
    MR = namedtuple('MR', 'pos, category, deps') 
    for (deps, tags) in parses:
        depDict = {}
        for line in deps:
            (word, dep, rest) = line.split(' ', 2)
            word = preprocess_word(word)
            if word not in string.punctuation:
                depDict[word] = dep
        for tag in tags:
            (word, pos, cat) = tag.split('|')
            word = preprocess_word(word)
            cat = re.sub(r'\[.*?\]', '', cat)
            if 'NP' in cat:
                cat = cat.replace('NP', 'N')
            mr = MR(pos, cat, depDict.get(word))
            if word not in string.punctuation:
                if mr not in catLex[word]:
                    catLex[word].append(mr)
    return catLex


# ======================================================
# Step 3: Determine logical predicate(s) for each word.
# ======================================================

def build_preds(catLex):
    words = defaultdict(list)
    categories = defaultdict(list)
    for (word, mrs) in catLex.items():
        for mr in mrs:
            try:
                semCat = SemanticCategory(word, mr.pos, mr.deps, opts.questions)
            except Exception as e:
                line = "Error creating expression for '{0}' mr({1} {2} {3})\n"
                sys.stderr.write(line.format(word, mr.pos, mr.category, mr.deps))
                print(traceback.format_exc())
                continue

            key = (word, mr.category)
            if semCat.getExpression() not in words[key]:
                words[key].append(semCat.getExpression())
            if semCat.getBaseExpression() not in categories[mr.category]:
                categories[mr.category].append(semCat.getBaseExpression())
    return (words, categories)

def write_predLex(words, categories, filename):
    """
    Saves predLex to filename.
    """
    with io.open(filename, 'wt', encoding='utf-8') as out:
        out.write('# WORDS\n')
        word_list = sorted(words.items(), key=lambda i: i[0][0]) ##
        for ((word, cat), preds) in word_list:
            for pred in preds:
                out.write('{0} :: {1} :: {2}\n'.format(word, cat, pred))
        out.write('# CATEGORIES\n')
        cat_list = sorted(categories.items(), key=lambda c: len(c[0])) ##
        for (cat, preds) in cat_list:
            for pred in preds:
                out.write('{0} :: {1}\n'.format(cat, pred))
    sys.stderr.write("predLex written to {0}.\n".format(filename))

def main():
    if not opts.infile or not opts.outfile:
        line = "Usage build_predlex [-i <path/to/inputfile>] [-o <path/to/outputfile>]\n"
        sys.stderr.write(line)
        return

    parses = get_parses(opts.infile)
    catLex = build_catLex(parses)
    (word_dict, category_dict) = build_preds(catLex)
    write_predLex(word_dict, category_dict, opts.outfile)


if __name__ == '__main__':
    main()
